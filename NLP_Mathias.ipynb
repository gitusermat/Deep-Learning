{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitusermat/Deep-Learning/blob/main/NLP_Mathias.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_ym8B_pfNLNX",
        "outputId": "11afe336-909e-4fa1-dfcd-c8494ea4cada"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install scikit-learn\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hpuoCoKHNTp2",
        "outputId": "ce2270ac-f962-4750-dbff-f3774ac62dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        id                                               text  \\\n",
            "0  eng_train_track_a_00001                                But not very happy.   \n",
            "1  eng_train_track_a_00002  Well she's not gon na last the whole song like...   \n",
            "2  eng_train_track_a_00003  She sat at her Papa's recliner sofa only to mo...   \n",
            "3  eng_train_track_a_00004                    Yes, the Oklahoma city bombing.   \n",
            "4  eng_train_track_a_00005                       They were dancing to Bolero.   \n",
            "\n",
            "   Anger  Fear  Joy  Sadness  Surprise  \n",
            "0      0     0    1        1         0  \n",
            "1      0     0    1        0         0  \n",
            "2      0     0    0        0         0  \n",
            "3      1     1    0        1         1  \n",
            "4      0     0    1        0         0  \n",
            "Training Samples: 2214, Validation Samples: 554\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset (assuming it's in CSV format)\n",
        "data = pd.read_csv(\"eng.csv\")\n",
        "\n",
        "# Let's inspect the data\n",
        "print(data.head())\n",
        "\n",
        "# Preprocessing: Lowercase the text\n",
        "data['text'] = data['text'].str.lower()\n",
        "\n",
        "# Splitting into training and validation sets (80/20 split)\n",
        "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Separate features and labels\n",
        "X_train = train_data['text'].tolist()\n",
        "y_train = train_data[['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']].values\n",
        "\n",
        "X_val = val_data['text'].tolist()\n",
        "y_val = val_data[['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']].values\n",
        "\n",
        "print(f\"Training Samples: {len(X_train)}, Validation Samples: {len(X_val)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aU5vgOEuNf3q",
        "outputId": "6c012ed6-51ec-4852-bc94-ae074c84883e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Encoded Shape: torch.Size([2214, 107])\n",
            "Validation Encoded Shape: torch.Size([554, 117])\n"
          ]
        }
      ],
      "source": [
        "from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
        "import torch\n",
        "\n",
        "# Load the pre-trained XLM-R tokenizer and model\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "xlm_roberta_model = XLMRobertaModel.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "# Function to tokenize and encode text for XLM-R\n",
        "def tokenize_and_encode(text_list):\n",
        "    encoding = tokenizer(\n",
        "        text_list,\n",
        "        max_length=128,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    return encoding\n",
        "\n",
        "# Tokenize and encode the training and validation text\n",
        "X_train_encoded = tokenize_and_encode(X_train)\n",
        "X_val_encoded = tokenize_and_encode(X_val)\n",
        "\n",
        "# Example to show encoded text shapes\n",
        "print(\"Training Encoded Shape:\", X_train_encoded['input_ids'].shape)\n",
        "print(\"Validation Encoded Shape:\", X_val_encoded['input_ids'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CkaPJq9KNkDx",
        "outputId": "5d0264cb-ccab-4108-ecd8-ffb1121e5562"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EmotionClassifier(\n",
              "  (xlm_roberta): XLMRobertaModel(\n",
              "    (embeddings): XLMRobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): XLMRobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): XLMRobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import XLMRobertaModel\n",
        "\n",
        "# Define the model using XLM-RoBERTa\n",
        "class EmotionClassifier(nn.Module):\n",
        "    def __init__(self, xlm_roberta_model, num_labels):\n",
        "        super(EmotionClassifier, self).__init__()\n",
        "        self.xlm_roberta = xlm_roberta_model\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(xlm_roberta_model.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.xlm_roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = outputs.last_hidden_state\n",
        "        cls_output = hidden_state[:, 0, :]  # Use [CLS] token for classification\n",
        "        cls_output = self.dropout(cls_output)\n",
        "        logits = self.classifier(cls_output)\n",
        "        return logits\n",
        "\n",
        "# Load XLM-RoBERTa and initialize the model\n",
        "num_labels = 5  # Number of emotion classes: Anger, Fear, Joy, Sadness, Surprise\n",
        "model = EmotionClassifier(xlm_roberta_model, num_labels)\n",
        "\n",
        "# Check if GPU is available and move the model to GPU if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSZSmhb9N35o"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "# Optimizer\n",
        "# Use a slightly increased learning rate to speed up convergence and regularization to prevent overfitting.\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwpD57uZN8CN",
        "outputId": "8150badf-c4ed-4add-b5a7-bde1cd0e759f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Alignment:\n",
            "Input IDs shape: torch.Size([2214, 107])\n",
            "Attention Mask shape: torch.Size([2214, 107])\n",
            "Labels shape: 2214\n",
            "After Alignment:\n",
            "Input IDs shape: torch.Size([2214, 107])\n",
            "Attention Mask shape: torch.Size([2214, 107])\n",
            "Labels shape: torch.Size([2214, 5])\n",
            "Batch Input IDs Shape: torch.Size([8, 107])\n",
            "Batch Attention Mask Shape: torch.Size([8, 107])\n",
            "Batch Labels Shape: torch.Size([8, 5])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Debugging: Print sizes of input and labels before processing\n",
        "print(\"Before Alignment:\")\n",
        "print(\"Input IDs shape:\", X_train_encoded['input_ids'].shape)\n",
        "print(\"Attention Mask shape:\", X_train_encoded['attention_mask'].shape)\n",
        "print(\"Labels shape:\", len(y_train))\n",
        "\n",
        "# Ensure the labels match the number of tokenized inputs\n",
        "min_size = min(X_train_encoded['input_ids'].shape[0], len(y_train))\n",
        "X_train_encoded['input_ids'] = X_train_encoded['input_ids'][:min_size]\n",
        "X_train_encoded['attention_mask'] = X_train_encoded['attention_mask'][:min_size]\n",
        "y_train = y_train[:min_size]\n",
        "\n",
        "min_size = min(X_val_encoded['input_ids'].shape[0], len(y_val))\n",
        "X_val_encoded['input_ids'] = X_val_encoded['input_ids'][:min_size]\n",
        "X_val_encoded['attention_mask'] = X_val_encoded['attention_mask'][:min_size]\n",
        "y_val = y_val[:min_size]\n",
        "\n",
        "# Convert labels to tensors with appropriate shape\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)  # Shape: (num_samples, num_labels)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)      # Shape: (num_samples, num_labels)\n",
        "\n",
        "# Verify shapes after adjustment\n",
        "print(\"After Alignment:\")\n",
        "print(\"Input IDs shape:\", X_train_encoded['input_ids'].shape)\n",
        "print(\"Attention Mask shape:\", X_train_encoded['attention_mask'].shape)\n",
        "print(\"Labels shape:\", y_train_tensor.shape)\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(\n",
        "    X_train_encoded['input_ids'],\n",
        "    X_train_encoded['attention_mask'],\n",
        "    y_train_tensor\n",
        ")\n",
        "val_dataset = TensorDataset(\n",
        "    X_val_encoded['input_ids'],\n",
        "    X_val_encoded['attention_mask'],\n",
        "    y_val_tensor\n",
        ")\n",
        "\n",
        "# Create DataLoaders\n",
        "# Reduced batch size to ensure stability when training on multilingual data\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)  # Adjust batch size as per GPU memory\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Verify DataLoader functionality\n",
        "for batch in train_loader:\n",
        "    input_ids, attention_mask, labels = batch\n",
        "    print(\"Batch Input IDs Shape:\", input_ids.shape)\n",
        "    print(\"Batch Attention Mask Shape:\", attention_mask.shape)\n",
        "    print(\"Batch Labels Shape:\", labels.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.utils\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import time\n",
        "\n",
        "# Mixed precision training setup (Updated deprecated usage)\n",
        "scaler = torch.amp.GradScaler()\n",
        "\n",
        "# Define the training loop with improvements\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler=None, epochs=5, patience=2):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    wait = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Training phase\n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "            input_ids, attention_mask, labels = batch\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Use autocast for mixed precision training\n",
        "            with torch.amp.autocast(device_type='cuda'):\n",
        "                logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                loss = criterion(logits, labels)\n",
        "\n",
        "            # Backward pass and optimization using gradient scaling\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # Clip the gradients to avoid exploding gradients\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            # Perform optimization\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            # Accumulate the loss to calculate the average later\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Print every 50 batches to track progress\n",
        "            if (batch_idx + 1) % 50 == 0:\n",
        "                print(f\"Epoch [{epoch + 1}/{epochs}], Step [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        # Calculate average training loss for the epoch\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        print(f\"Epoch {epoch + 1}, Average Training Loss: {avg_train_loss:.4f}, Time taken: {time.time() - start_time:.2f}s\")\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        total_val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                input_ids, attention_mask, labels = batch\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                with torch.amp.autocast(device_type='cuda'):\n",
        "                    logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                    val_loss = criterion(logits, labels)\n",
        "                    total_val_loss += val_loss.item()\n",
        "\n",
        "        # Calculate average validation loss for the epoch\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        print(f\"Epoch {epoch + 1}, Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # Scheduler step (if used)\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Early stopping logic\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            wait = 0\n",
        "            print(f\"Validation loss improved to {best_val_loss:.4f}, resetting patience.\")\n",
        "        else:\n",
        "            wait += 1\n",
        "            print(f\"No improvement in validation loss. Patience: {wait}/{patience}\")\n",
        "            if wait >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# Scheduler - Use OneCycleLR to have more dynamic adjustments to learning rate\n",
        "scheduler = OneCycleLR(optimizer, max_lr=3e-5, epochs=5, steps_per_epoch=len(train_loader))\n",
        "\n",
        "# Criterion for multi-label classification\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Run the training loop with corrected settings\n",
        "train_losses, val_losses = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    epochs=3,  # Reduced number of epochs to prevent overfitting\n",
        "    patience=2  # Lower patience to stop training early if overfitting starts\n",
        ")"
      ],
      "metadata": {
        "id": "GVY40GUvvnVr",
        "outputId": "7edec59a-0780-40f1-f449-c65111e46e6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mC-v3UvVZIA"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "1gNgArf-VaP3",
        "outputId": "3a318e00-8db5-4966-fc9c-26ca69cc3e8a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_losses' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-df6ac65b772b>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Plot the losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the loss curves\n",
        "def plot_loss(train_losses, val_losses):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, train_losses, label='Training Loss', marker='o')\n",
        "    plt.plot(epochs, val_losses, label='Validation Loss', marker='o')\n",
        "\n",
        "    plt.title('Training and Validation Loss over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Plot the losses\n",
        "plot_loss(train_losses, val_losses)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvpZh1jIVWnF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGHRcmZDN-EZ",
        "outputId": "896d1363-5df7-4d67-9077-5844a6dfaa25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Micro F1-score: 0.6575\n",
            "Precision: 0.6675\n",
            "Recall: 0.6479\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.25      0.31        61\n",
            "           1       0.71      0.86      0.78       314\n",
            "           2       0.72      0.53      0.61       134\n",
            "           3       0.58      0.58      0.58       171\n",
            "           4       0.68      0.56      0.61       172\n",
            "\n",
            "   micro avg       0.67      0.65      0.66       852\n",
            "   macro avg       0.62      0.56      0.58       852\n",
            "weighted avg       0.66      0.65      0.65       852\n",
            " samples avg       0.61      0.60      0.58       852\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Get predictions and calculate F1-score\n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            preds = torch.sigmoid(logits).cpu().numpy()  # Convert to probabilities\n",
        "\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "            all_preds.append((preds > 0.5).astype(int))  # Apply threshold\n",
        "\n",
        "    # Flatten the lists\n",
        "    all_labels = np.concatenate(all_labels, axis=0)\n",
        "    all_preds = np.concatenate(all_preds, axis=0)\n",
        "\n",
        "    # Calculate metrics\n",
        "    f1 = f1_score(all_labels, all_preds, average='micro')\n",
        "    precision = precision_score(all_labels, all_preds, average='micro')\n",
        "    recall = recall_score(all_labels, all_preds, average='micro')\n",
        "    print(f\"Micro F1-score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds))\n",
        "\n",
        "# Evaluate on validation data\n",
        "evaluate(model, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYvXOIzFThEk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define your emotion labels (ensure these are in the same order as your model's output)\n",
        "emotion_labels = ['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']\n",
        "\n",
        "# Helper function to decode predictions from binary array to emotion labels\n",
        "def decode_predictions(predictions):\n",
        "    decoded_preds = []\n",
        "    for pred in predictions:\n",
        "        decoded_preds.append([emotion_labels[i] for i, val in enumerate(pred) if val == 1])\n",
        "    return decoded_preds\n",
        "\n",
        "# Helper function to decode true labels\n",
        "def decode_true_labels(labels):\n",
        "    decoded_labels = []\n",
        "    for label in labels:\n",
        "        decoded_labels.append([emotion_labels[i] for i, val in enumerate(label) if val == 1])\n",
        "    return decoded_labels\n",
        "\n",
        "# Function to visualize output\n",
        "def visualize_output(model, data_loader, text_data):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    input_texts = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "\n",
        "            # Forward pass through the model\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            preds = torch.sigmoid(outputs).cpu().numpy()  # Convert logits to probabilities\n",
        "\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "            all_preds.append(preds > 0.5)  # Apply threshold (0.5)\n",
        "\n",
        "    # Flatten predictions and labels\n",
        "    all_labels = np.concatenate(all_labels, axis=0)\n",
        "    all_preds = np.concatenate(all_preds, axis=0)\n",
        "\n",
        "    # Decode predictions and true labels to emotion labels\n",
        "    predicted_emotions = decode_predictions(all_preds)\n",
        "    true_emotions = decode_true_labels(all_labels)\n",
        "\n",
        "    # Create a DataFrame to visualize the output\n",
        "    results_df = pd.DataFrame({\n",
        "        'Text': text_data,  # Original text (before tokenization)\n",
        "        'Predicted Emotions': predicted_emotions,\n",
        "        'True Emotions': true_emotions\n",
        "    })\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# Example usage:\n",
        "# Assuming `X_val` contains the original text snippets used for validation\n",
        "results_df = visualize_output(model, val_loader, X_val)\n",
        "\n",
        "# Display the first few rows of predictions vs actual\n",
        "print(results_df.head(10))  # Show first 10 samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQaMVScjQR-T"
      },
      "outputs": [],
      "source": [
        "# # Convert predictions to readable format (e.g., list of labels)\n",
        "# emotion_labels = ['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']\n",
        "\n",
        "# def decode_predictions(predictions):\n",
        "#     decoded_preds = []\n",
        "#     for pred in predictions:\n",
        "#         decoded_preds.append([emotion_labels[i] for i, val in enumerate(pred) if val == 1])\n",
        "#     return decoded_preds\n",
        "\n",
        "# # Decode predictions and true labels (if available)\n",
        "# predicted_emotions = decode_predictions(all_preds)\n",
        "# true_emotions = decode_predictions(y_val)\n",
        "\n",
        "# # Combine into a DataFrame to visualize\n",
        "# results_df = pd.DataFrame({'Text': X_val, 'Predicted Emotions': predicted_emotions, 'True Emotions': true_emotions})\n",
        "\n",
        "# # Show the first few rows\n",
        "# print(results_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLGcQHH6PNK7"
      },
      "outputs": [],
      "source": [
        "### result on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCjcPRYdPmbZ"
      },
      "outputs": [],
      "source": [
        "# Assuming the new test data is a CSV\n",
        "new_data = pd.read_csv(\"eng_a.csv\")\n",
        "\n",
        "# Inspect the new data\n",
        "print(new_data.head())\n",
        "\n",
        "# Preprocessing: Ensure text is lowercased\n",
        "new_data['text'] = new_data['text'].str.lower()\n",
        "\n",
        "# Extract the text from the new data\n",
        "X_new = new_data['text'].tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MQ_sOc5Pslb"
      },
      "outputs": [],
      "source": [
        "# Tokenize and encode the new data\n",
        "X_new_encoded = tokenize_and_encode(X_new)\n",
        "\n",
        "# Example to show the shape of the tokenized new data\n",
        "print(X_new_encoded['input_ids'].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "26KL5JjkPy9U",
        "outputId": "974913de-2d1a-4d4a-bb43-3a325d3c4121"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b4149e3130b3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Set model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Prepare DataLoader for new data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Prepare DataLoader for new data\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "new_dataset = TensorDataset(X_new_encoded['input_ids'], X_new_encoded['attention_mask'])\n",
        "new_loader = DataLoader(new_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Get predictions\n",
        "all_new_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in new_loader:\n",
        "        input_ids, attention_mask = batch\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "\n",
        "        # Forward pass to get logits\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        preds = torch.sigmoid(outputs).cpu().numpy()  # Convert logits to probabilities\n",
        "\n",
        "        # Apply threshold (e.g., 0.5)\n",
        "        all_new_preds.append(preds > 0.5)\n",
        "\n",
        "# Convert list of predictions to a numpy array\n",
        "all_new_preds = np.concatenate(all_new_preds, axis=0)\n",
        "\n",
        "# Display predictions (will be a binary matrix: 1 for present, 0 for absent)\n",
        "print(all_new_preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b09kNU7yP2xb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Ae7oFdqZQAs_",
        "outputId": "33d8319b-cd69-4064-bb08-898e99ae9c78"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1606675da852>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'emotion_detection_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# To load the model later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model = YourModelClass()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'emotion_detection_model.pth')\n",
        "\n",
        "# To load the model later\n",
        "# model = YourModelClass()\n",
        "# model.load_state_dict(torch.load('emotion_detection_model.pth'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uhco9tgXacvx"
      },
      "outputs": [],
      "source": [
        "! pip install SpeechRecognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAiHWFoYaW5x"
      },
      "outputs": [],
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "# Convert speech to text\n",
        "def speech_to_text():\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.Microphone() as source:\n",
        "        print(\"Please say something...\")\n",
        "        audio = recognizer.listen(source)\n",
        "\n",
        "        try:\n",
        "            print(\"Recognizing...\")\n",
        "            text = recognizer.recognize_google(audio)\n",
        "            print(f\"Text: {text}\")\n",
        "            return text\n",
        "        except sr.UnknownValueError:\n",
        "            print(\"Google Speech Recognition could not understand the audio\")\n",
        "            return None\n",
        "        except sr.RequestError as e:\n",
        "            print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
        "            return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K57AeAi_axso"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel\n",
        "import torch.nn as nn\n",
        "\n",
        "# Update model class to match the saved model's architecture\n",
        "class EmotionClassifier(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(EmotionClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)  # Change 'out' to 'classifier'\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        pooled_output = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )[1]\n",
        "        output = self.drop(pooled_output)\n",
        "        return self.classifier(output)  # Change 'out' to 'classifier'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZfNhr59Z0yv"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "\n",
        "# Update the load_model function\n",
        "def load_model():\n",
        "    n_classes = 5  # Number of emotions\n",
        "    model = EmotionClassifier(n_classes)  # Replace with your model class\n",
        "    model.load_state_dict(torch.load('emotion_detection_model.pth'))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "# Predict emotions from text\n",
        "def predict_emotions(text, model, tokenizer):\n",
        "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        predictions = torch.sigmoid(outputs).cpu().numpy()\n",
        "\n",
        "    # Apply threshold (0.5)\n",
        "    emotion_labels = ['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']\n",
        "    predicted_emotions = [emotion_labels[i] for i, val in enumerate(predictions[0]) if val > 0.5]\n",
        "\n",
        "    return predicted_emotions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDaLFnRYaf32"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "def load_model():\n",
        "    # Number of emotions (adjust if needed for your specific use case)\n",
        "    n_classes = 5\n",
        "\n",
        "    # Load a pre-trained BERT model for sequence classification\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        'bert-base-uncased',\n",
        "        num_labels=n_classes\n",
        "    )\n",
        "\n",
        "    # Load model weights (adjust the path to where your model is saved)\n",
        "    model.load_state_dict(torch.load('emotion_detection_model.pth', map_location=torch.device('cpu')))\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    return model\n",
        "\n",
        "def main():\n",
        "    # Load model and tokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = load_model()\n",
        "\n",
        "    # Convert speech to text (assuming this function is defined elsewhere)\n",
        "    text = speech_to_text()\n",
        "\n",
        "    if text:\n",
        "        # Predict emotions\n",
        "        emotions = predict_emotions(text, model, tokenizer)\n",
        "\n",
        "        if emotions:\n",
        "            print(f\"Predicted emotions: {', '.join(emotions)}\")\n",
        "        else:\n",
        "            print(\"No emotions detected.\")\n",
        "    else:\n",
        "        print(\"No text to process.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrJkQvbvbHtu"
      },
      "outputs": [],
      "source": [
        "!pip install pyaudio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQ3D3QWlaiYA"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import io\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import speech_recognition as sr\n",
        "from google.colab import output\n",
        "from IPython.display import display, Javascript\n",
        "\n",
        "# Function to record audio\n",
        "def record_audio():\n",
        "    # JavaScript to record audio\n",
        "    display(Javascript('''\n",
        "    async function recordAudio() {\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
        "        const mediaRecorder = new MediaRecorder(stream);\n",
        "        const audioChunks = [];\n",
        "\n",
        "        mediaRecorder.ondataavailable = event => {\n",
        "            audioChunks.push(event.data);\n",
        "        };\n",
        "\n",
        "        mediaRecorder.onstop = async () => {\n",
        "            const audioBlob = new Blob(audioChunks);\n",
        "            const arrayBuffer = await audioBlob.arrayBuffer();\n",
        "            const base64String = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));\n",
        "            google.colab.kernel.invokeFunction('notebook.recordingComplete', [base64String], {});\n",
        "        };\n",
        "\n",
        "        mediaRecorder.start();\n",
        "        await new Promise(resolve => setTimeout(resolve, 5000)); // Record for 5 seconds\n",
        "        mediaRecorder.stop();\n",
        "    }\n",
        "    recordAudio();\n",
        "    '''))\n",
        "\n",
        "# Function to handle audio recording completion\n",
        "def handle_recording_complete(base64_audio):\n",
        "    # Decode the base64 audio\n",
        "    audio_data = io.BytesIO(base64.b64decode(base64_audio))\n",
        "\n",
        "    # Use SpeechRecognition to convert audio to text\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_data) as source:\n",
        "        audio = recognizer.record(source)  # Read the entire audio file\n",
        "\n",
        "        try:\n",
        "            print(\"Recognizing...\")\n",
        "            text = recognizer.recognize_google(audio)\n",
        "            print(f\"Text: {text}\")\n",
        "            return text\n",
        "        except sr.UnknownValueError:\n",
        "            print(\"Google Speech Recognition could not understand the audio\")\n",
        "            return None\n",
        "        except sr.RequestError as e:\n",
        "            print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
        "            return None\n",
        "\n",
        "# Define the EmotionClassifier model\n",
        "class EmotionClassifier(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(EmotionClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)[1]\n",
        "        output = self.drop(pooled_output)\n",
        "        return self.classifier(output)\n",
        "\n",
        "# Load the model\n",
        "def load_model():\n",
        "    n_classes = 5  # Number of emotions\n",
        "    model = EmotionClassifier(n_classes)\n",
        "    model.load_state_dict(torch.load('emotion_detection_model.pth', map_location=torch.device('cpu')))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Predict emotions from text\n",
        "def predict_emotions(text, model, tokenizer):\n",
        "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        predictions = torch.sigmoid(outputs).cpu().numpy()\n",
        "\n",
        "    # Apply threshold (0.5)\n",
        "    emotion_labels = ['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']\n",
        "    predicted_emotions = [emotion_labels[i] for i, val in enumerate(predictions[0]) if val > 0.5]\n",
        "\n",
        "    return predicted_emotions\n",
        "\n",
        "def main():\n",
        "    # Load model and tokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = load_model()\n",
        "\n",
        "    # Record audio and convert to text\n",
        "    print(\"Please record your audio...\")\n",
        "    record_audio()\n",
        "\n",
        "    # This function handles audio conversion and returns the transcribed text\n",
        "    text = handle_recording_complete(audio_data)\n",
        "\n",
        "    if text:\n",
        "        # Predict emotions\n",
        "        emotions = predict_emotions(text, model, tokenizer)\n",
        "\n",
        "        if emotions:\n",
        "            print(f\"Predicted emotions: {', '.join(emotions)}\")\n",
        "        else:\n",
        "            print(\"No emotions detected.\")\n",
        "    else:\n",
        "        print(\"No text to process.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ROzuhnacGT8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}